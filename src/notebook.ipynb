{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0tMFwpE0llOs",
        "45MgVp9hi-Ug",
        "hCSlOuBV8MFx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors in Pytorch"
      ],
      "metadata": {
        "id": "fi-JfJyW4M3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What are tensors?\n",
        "Anything that arrays (numpy arrays) do in one dimension; tensors do them in n-dimension.\n",
        "\n",
        "---\n",
        "\n",
        "### Why are tensors useful?\n",
        "- Mathematical operations.\n",
        "- Representation of real-world data.\n",
        "- **Efficient computations:** Tensors are optimized for hardware acceleration.\n",
        "\n",
        "---\n",
        "\n",
        "### Why are are tensors used in DL?\n",
        "- Data storage.\n",
        "- Weights and biases.\n",
        "- Matrix based operations.\n",
        "- Training process.\n"
      ],
      "metadata": {
        "id": "Ba-UQu4G4QSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Import"
      ],
      "metadata": {
        "id": "WYIFmN2O69Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dLOqX8h6_bT",
        "outputId": "29593ec3-de32-4e69-a0c4-f272a651bf06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFha0IVG7D-t",
        "outputId": "8db811c9-941d-454a-c587-0c7e49cc343c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Tensors"
      ],
      "metadata": {
        "id": "sbvHcp_87R-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.empty(2, 3))\n",
        "print(torch.zeros(2, 3))\n",
        "print(torch.ones(2, 3))\n",
        "print(torch.rand(2, 3))\n",
        "\n",
        "# To acheive reproducability when it comes to randomly generating tensors\n",
        "torch.manual_seed(42)\n",
        "print(torch.rand(2, 3))\n",
        "\n",
        "# To create a custom tensor\n",
        "print(torch.tensor([[1, 2, 3], [4, 5, 6]]))\n",
        "\n",
        "# Other ways\n",
        "print(torch.arange(0, 10, 2))\n",
        "print(torch.linspace(0, 10, 5))\n",
        "print(torch.eye(5))  # To get an identity matrix of shape (5, 5)\n",
        "print(torch.full((2, 3), 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N2CGpO17T09",
        "outputId": "23b081d2-4722-49dc-d727-c3fb99211722"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.1306e-09, 4.4710e-41, 7.1780e-34],\n",
            "        [0.0000e+00, 4.4842e-44, 0.0000e+00]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0.0916, 0.0399, 0.8603],\n",
            "        [0.9275, 0.4440, 0.3461]])\n",
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([0, 2, 4, 6, 8])\n",
            "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n",
            "tensor([[5, 5, 5],\n",
            "        [5, 5, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with Tensors"
      ],
      "metadata": {
        "id": "yRgmLcV99GG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(t.shape)\n",
        "\n",
        "# To create a tensors replicating the shape of an existing tensor\n",
        "print(torch.empty_like(t))\n",
        "print(torch.zeros_like(t))\n",
        "print(torch.ones_like(t))\n",
        "print(torch.rand_like(t)) # This line will generate an error; as rand generates floats (between 0 and 1). For, this you need to understand the data types."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "38uMkhAT9Mv3",
        "outputId": "7d800402-9767-4bc8-ffed-2266a5613c8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "tensor([[              0,       137728928,       118334912],\n",
            "        [134062563048720,               0,               0]])\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "\"check_uniform_bounds\" not implemented for 'Long'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a70f2636fc30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: \"check_uniform_bounds\" not implemented for 'Long'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding Tensor Data-types"
      ],
      "metadata": {
        "id": "hf72acg4MXwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "t_1 = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "print(t.dtype)\n",
        "print(t_1.dtype)\n",
        "print(torch.tensor([1.0, 2.0, 3.0], dtype=torch.int32))\n",
        "print(torch.tensor([1, 2, 3], dtype=torch.float64))\n",
        "print(t.to(torch.float64))  # To convert a datatype from one to another\n",
        "\n",
        "t = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.long)\n",
        "print(t.dtype)\n",
        "\n",
        "t = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.double)\n",
        "print(t.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b3WgzmPMbUW",
        "outputId": "ae8820b7-1f48-4928-b14b-462e5fa38f44"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n",
            "tensor([1, 2, 3], dtype=torch.int32)\n",
            "tensor([1., 2., 3.], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "torch.int64\n",
            "torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Therefore, the solution to the above problem can be\n",
        "print(torch.rand_like(t, dtype=torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enfO9-JnNWOu",
        "outputId": "32360adf-5831-43be-eb32-a57f22441adc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2852, 0.1391, 0.2684],\n",
            "        [0.9310, 0.3423, 0.6405]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing Operations on Tensors"
      ],
      "metadata": {
        "id": "YU9H0WrhOa3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Scalar operations"
      ],
      "metadata": {
        "id": "svH5SpfwOnK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(t + 2)\n",
        "print(t - 2)\n",
        "print(t * 2)\n",
        "print(t / 2)\n",
        "print(t**2)\n",
        "print((t*100)//2)\n",
        "print(((t*100)//2)%2)\n",
        "\n",
        "print(t)  # From here you can observe that scalr operations are not inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWlZTdHKOu5N",
        "outputId": "23bc0e8e-5e44-48d3-b14b-9000bf16a21d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[-1,  0,  1],\n",
            "        [ 2,  3,  4]])\n",
            "tensor([[ 2,  4,  6],\n",
            "        [ 8, 10, 12]])\n",
            "tensor([[0.5000, 1.0000, 1.5000],\n",
            "        [2.0000, 2.5000, 3.0000]])\n",
            "tensor([[ 1,  4,  9],\n",
            "        [16, 25, 36]])\n",
            "tensor([[ 50, 100, 150],\n",
            "        [200, 250, 300]])\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Element-wise operations"
      ],
      "metadata": {
        "id": "__zmfkvIPes_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
        "\n",
        "print(a + b)\n",
        "print(a - b)\n",
        "print(a * b)\n",
        "print(a / b)\n",
        "print(a**b)\n",
        "print((a*100)//b)\n",
        "print(((a*100)//b)%2)\n",
        "\n",
        "# Element-wise operations are also not inplace\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m83XYKisPlVI",
        "outputId": "f2cb830e-41ff-4afc-d72a-4558c4efbac1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 8, 10, 12],\n",
            "        [14, 16, 18]])\n",
            "tensor([[-6, -6, -6],\n",
            "        [-6, -6, -6]])\n",
            "tensor([[ 7, 16, 27],\n",
            "        [40, 55, 72]])\n",
            "tensor([[0.1429, 0.2500, 0.3333],\n",
            "        [0.4000, 0.4545, 0.5000]])\n",
            "tensor([[         1,        256,      19683],\n",
            "        [   1048576,   48828125, 2176782336]])\n",
            "tensor([[14, 25, 33],\n",
            "        [40, 45, 50]])\n",
            "tensor([[0, 1, 1],\n",
            "        [0, 1, 0]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[ 7,  8,  9],\n",
            "        [10, 11, 12]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Reduction operations"
      ],
      "metadata": {
        "id": "-le_wg8vQ3d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([1.7, -2.2, 3.5, 4.5, 5.7])\n",
        "\n",
        "print(t.sum())\n",
        "print(torch.sum(t, dim=0))  # For, along columns (and dim=1 for along rows)\n",
        "print(t.prod())\n",
        "print(torch.prod(t, dim=0))\n",
        "print(t.mean())\n",
        "print(torch.mean(t, dim=0))\n",
        "print(t.std())\n",
        "print(torch.std(t, dim=0))\n",
        "print(t.var())\n",
        "print(torch.var(t, dim=0))\n",
        "print(t.max())\n",
        "print(t.min())\n",
        "print(t.argmin())\n",
        "print(t.argmax())\n",
        "\n",
        "print(t)  # Not inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67s7nbxbQ6La",
        "outputId": "724602b8-6c03-49a7-cd38-b2a4a77b2afe"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(13.2000)\n",
            "tensor(13.2000)\n",
            "tensor(-335.7585)\n",
            "tensor(-335.7585)\n",
            "tensor(2.6400)\n",
            "tensor(2.6400)\n",
            "tensor(3.0770)\n",
            "tensor(3.0770)\n",
            "tensor(9.4680)\n",
            "tensor(9.4680)\n",
            "tensor(5.7000)\n",
            "tensor(-2.2000)\n",
            "tensor(1)\n",
            "tensor(4)\n",
            "tensor([ 1.7000, -2.2000,  3.5000,  4.5000,  5.7000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Other operations"
      ],
      "metadata": {
        "id": "YZwOD6vmP9L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([1.7, -2.2, 3.5, 4.5, 5.7])\n",
        "\n",
        "print(t.abs())\n",
        "print(t.sqrt())\n",
        "print(t.neg())\n",
        "print(t.round())\n",
        "print(t.ceil())\n",
        "print(t.floor())\n",
        "print(t.clamp(min=0, max=3))\n",
        "\n",
        "print(t)  # Also, not inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJPmgqMLQAHH",
        "outputId": "b01962eb-ae08-463a-a24f-c2ddf8495d58"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.7000, 2.2000, 3.5000, 4.5000, 5.7000])\n",
            "tensor([1.3038,    nan, 1.8708, 2.1213, 2.3875])\n",
            "tensor([-1.7000,  2.2000, -3.5000, -4.5000, -5.7000])\n",
            "tensor([ 2., -2.,  4.,  4.,  6.])\n",
            "tensor([ 2., -2.,  4.,  5.,  6.])\n",
            "tensor([ 1., -3.,  3.,  4.,  5.])\n",
            "tensor([1.7000, 0.0000, 3.0000, 3.0000, 3.0000])\n",
            "tensor([ 1.7000, -2.2000,  3.5000,  4.5000,  5.7000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Matrix operations"
      ],
      "metadata": {
        "id": "uTwOp_OwSK4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1, 2], [4, 5]])\n",
        "b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
        "\n",
        "print(a.matmul(b))\n",
        "print(torch.matmul(a, b))\n",
        "print(a @ b)\n",
        "\n",
        "a_1 = torch.tensor([1, 2, 3])\n",
        "b_1 = torch.tensor([4, 5, 6])\n",
        "\n",
        "print(a_1.dot(b_1))\n",
        "print(torch.dot(a_1, b_1))\n",
        "\n",
        "print(torch.transpose(a, 0, 1)) # Swapping dimensions 0 (columns) by 1 (rows)\n",
        "\n",
        "# Here, the following two operation require the data to be in floating point or complex data-types\n",
        "print(torch.inverse(a.to(torch.double)))\n",
        "print(torch.det(a.to(torch.double)))\n",
        "\n",
        "# Also, not inplace\n",
        "print(a)\n",
        "print(b)\n",
        "print(a_1)\n",
        "print(b_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZQnyxNlSRpk",
        "outputId": "755a0b8c-c68c-4354-e60b-9785c24d6923"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27, 30, 33],\n",
            "        [78, 87, 96]])\n",
            "tensor([[27, 30, 33],\n",
            "        [78, 87, 96]])\n",
            "tensor([[27, 30, 33],\n",
            "        [78, 87, 96]])\n",
            "tensor(32)\n",
            "tensor(32)\n",
            "tensor([[1, 4],\n",
            "        [2, 5]])\n",
            "tensor([[-1.6667,  0.6667],\n",
            "        [ 1.3333, -0.3333]], dtype=torch.float64)\n",
            "tensor(-3., dtype=torch.float64)\n",
            "tensor([[1, 2],\n",
            "        [4, 5]])\n",
            "tensor([[ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "tensor([1, 2, 3])\n",
            "tensor([4, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Comparision operations"
      ],
      "metadata": {
        "id": "0THEkL0RU7M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(t == 2)\n",
        "print(t != 2)\n",
        "print(t > 2)\n",
        "print(t < 2)\n",
        "print(t >= 2)\n",
        "print(t <= 2)\n",
        "\n",
        "print(t)  # Not inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXeVq9jaU_AE",
        "outputId": "088c4cf8-cf01-4b95-aa21-943bbc6f0542"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False,  True, False],\n",
            "        [False, False, False]])\n",
            "tensor([[ True, False,  True],\n",
            "        [ True,  True,  True]])\n",
            "tensor([[False, False,  True],\n",
            "        [ True,  True,  True]])\n",
            "tensor([[ True, False, False],\n",
            "        [False, False, False]])\n",
            "tensor([[False,  True,  True],\n",
            "        [ True,  True,  True]])\n",
            "tensor([[ True,  True, False],\n",
            "        [False, False, False]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Special function based operations"
      ],
      "metadata": {
        "id": "XhlOSURRVGua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(torch.exp(t))\n",
        "print(torch.log(t))\n",
        "print(torch.sin(t))\n",
        "print(torch.cos(t))\n",
        "print(torch.tan(t))\n",
        "print(torch.sigmoid(t))\n",
        "print(torch.tanh(t))\n",
        "print(torch.relu(t))\n",
        "\n",
        "# Here, the softamax function requires the data to be floating point data-type\n",
        "print(torch.softmax(t.to(torch.double), dim=0))\n",
        "\n",
        "print(t)  # Not inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkfIeRScVJ97",
        "outputId": "4ca4c314-c1eb-47f1-ea72-2192683f37da"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  2.7183,   7.3891,  20.0855],\n",
            "        [ 54.5981, 148.4132, 403.4288]])\n",
            "tensor([[0.0000, 0.6931, 1.0986],\n",
            "        [1.3863, 1.6094, 1.7918]])\n",
            "tensor([[ 0.8415,  0.9093,  0.1411],\n",
            "        [-0.7568, -0.9589, -0.2794]])\n",
            "tensor([[ 0.5403, -0.4161, -0.9900],\n",
            "        [-0.6536,  0.2837,  0.9602]])\n",
            "tensor([[ 1.5574, -2.1850, -0.1425],\n",
            "        [ 1.1578, -3.3805, -0.2910]])\n",
            "tensor([[0.7311, 0.8808, 0.9526],\n",
            "        [0.9820, 0.9933, 0.9975]])\n",
            "tensor([[0.7616, 0.9640, 0.9951],\n",
            "        [0.9993, 0.9999, 1.0000]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[0.0474, 0.0474, 0.0474],\n",
            "        [0.9526, 0.9526, 0.9526]], dtype=torch.float64)\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Inplace operations"
      ],
      "metadata": {
        "id": "UcGf_3RcV6as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1, 2], [4, 5]])\n",
        "b = torch.tensor([[7, 8], [10, 11]])\n",
        "\n",
        "a.add_(b)\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# The underscore represents that you want to perform an inplace operation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5GqnsRrV89Z",
        "outputId": "57324ec6-b40a-40a3-bdc4-6388a9bc3f0c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 8, 10],\n",
            "        [14, 16]])\n",
            "tensor([[ 7,  8],\n",
            "        [10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Copying a tensor: Traditional assignment of tensors does work here, but the copy is not a deep copy; meaning that a change to the former will also be reflected in the later. Therefore, we use the clone method here."
      ],
      "metadata": {
        "id": "YUnlS8nmYfD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1, 2], [4, 5]])\n",
        "b = a\n",
        "\n",
        "a[0][0] = 100\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(id(a))\n",
        "print(id(b))\n",
        "\n",
        "# Therefore...\n",
        "a = torch.tensor([[1, 2], [4, 5]])\n",
        "b = a.clone()\n",
        "\n",
        "a[0][0] = 100\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(id(a))\n",
        "print(id(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf05j9hvYhy9",
        "outputId": "7de1d2f7-9582-4970-a627-94818ca2e3b8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[100,   2],\n",
            "        [  4,   5]])\n",
            "tensor([[100,   2],\n",
            "        [  4,   5]])\n",
            "137031499395248\n",
            "137031499395248\n",
            "tensor([[100,   2],\n",
            "        [  4,   5]])\n",
            "tensor([[1, 2],\n",
            "        [4, 5]])\n",
            "137031499383536\n",
            "137031499383344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Reshaping a tensor"
      ],
      "metadata": {
        "id": "z1LkCfwDlt96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(4, 4)\n",
        "\n",
        "print(t.reshape(2, 2, 2, 2))\n",
        "\n",
        "print(t.flatten())\n",
        "\n",
        "print(t)  # Not, inplace\n",
        "\n",
        "t = torch.rand(2, 3, 4)\n",
        "\n",
        "print(t.permute(2, 0, 1).shape)\n",
        "\n",
        "print(t)  # Not, inplace\n",
        "\n",
        "# Squeeze\n",
        "t = torch.rand(1, 1, 1, 2)\n",
        "\n",
        "print(t.squeeze().shape)\n",
        "\n",
        "# Unsqueeze\n",
        "t = torch.rand(2, 3)\n",
        "\n",
        "print(t.unsqueeze(dim=0).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-FTY8Xulwq9",
        "outputId": "32790243-cd3e-4f58-dd41-a3f622a5833d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[1., 1.],\n",
            "          [1., 1.]],\n",
            "\n",
            "         [[1., 1.],\n",
            "          [1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1.],\n",
            "          [1., 1.]],\n",
            "\n",
            "         [[1., 1.],\n",
            "          [1., 1.]]]])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "torch.Size([4, 2, 3])\n",
            "tensor([[[0.0921, 0.8987, 0.8410, 0.8655],\n",
            "         [0.7987, 0.1555, 0.0953, 0.7473],\n",
            "         [0.5916, 0.9969, 0.1437, 0.3681]],\n",
            "\n",
            "        [[0.4725, 0.4220, 0.8774, 0.8746],\n",
            "         [0.9291, 0.4621, 0.1010, 0.5196],\n",
            "         [0.2775, 0.4912, 0.4346, 0.9985]]])\n",
            "torch.Size([2])\n",
            "torch.Size([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Tensors on GPU"
      ],
      "metadata": {
        "id": "5kz4WMCJj8cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "l-Gdc91clUxA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "\n",
        "device = torch.device('cuda')\n",
        "print(device)\n",
        "\n",
        "# Creating an tensor directly on the GPU\n",
        "t = torch.tensor([[1, 2, 3], [4, 5, 6]], device=device)\n",
        "print(t)\n",
        "\n",
        "# Moving a tensor from CPU to GPU\n",
        "t_1 = t.to(device)\n",
        "print(t_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeY9OUESkALO",
        "outputId": "4ffb4b3a-6c18-434a-a100-8dbd0ee96c0b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], device='cuda:0')\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Comparision"
      ],
      "metadata": {
        "id": "dp24nBUikhRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Checking for GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"GPU not available, using CPU.\")\n",
        "\n",
        "# Defining tensor size\n",
        "size = 10000\n",
        "\n",
        "# Creating tensors on CPU and GPU\n",
        "cpu_tensor = torch.randn(size, size, device='cpu')\n",
        "gpu_tensor = torch.randn(size, size, device=device)\n",
        "\n",
        "\n",
        "# Matrix Multiplication on CPU\n",
        "start_time = time.time()\n",
        "cpu_result = cpu_tensor @ cpu_tensor\n",
        "end_time = time.time()\n",
        "cpu_time = end_time - start_time\n",
        "print(f\"CPU Matrix Multiplication Time: {cpu_time:.4f} seconds\")\n",
        "\n",
        "# Matrix Multiplication on GPU\n",
        "start_time = time.time()\n",
        "gpu_result = gpu_tensor @ gpu_tensor\n",
        "end_time = time.time()\n",
        "gpu_time = end_time - start_time\n",
        "print(f\"GPU Matrix Multiplication Time: {gpu_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "# Calculating and print speedup\n",
        "if torch.cuda.is_available():\n",
        "    speedup = cpu_time / gpu_time\n",
        "    print(f\"Speedup: {speedup:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M20T9foPkk_s",
        "outputId": "e5be34dd-a57f-4240-bc34-80ad3baa068a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Matrix Multiplication Time: 16.4210 seconds\n",
            "GPU Matrix Multiplication Time: 0.1420 seconds\n",
            "Speedup: 115.62x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting a Tensor from Pytorch and numpy and vice versa"
      ],
      "metadata": {
        "id": "8KH66K69o5jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# PyTorch tensor to NumPy array\n",
        "tensor = torch.randn(3, 4)\n",
        "numpy_array = tensor.numpy()\n",
        "print(f\"PyTorch Tensor:\\n{tensor}\")\n",
        "print(f\"NumPy Array:\\n{numpy_array}\")\n",
        "\n",
        "\n",
        "# NumPy array to PyTorch tensor\n",
        "numpy_array = np.random.rand(2, 3)\n",
        "tensor = torch.from_numpy(numpy_array)\n",
        "print(f\"NumPy Array:\\n{numpy_array}\")\n",
        "print(f\"PyTorch Tensor:\\n{tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us2ZJIt3pBW-",
        "outputId": "943a7cd4-fb6b-48c4-a8fd-84369003bbaf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Tensor:\n",
            "tensor([[-0.9128,  0.6102, -0.8808, -0.7788],\n",
            "        [-1.1297, -0.9826, -0.7798, -1.4082],\n",
            "        [ 1.3470,  2.0123, -0.7765, -0.4997]])\n",
            "NumPy Array:\n",
            "[[-0.9127962   0.610217   -0.880759   -0.77880424]\n",
            " [-1.1297117  -0.98264474 -0.7798132  -1.4082057 ]\n",
            " [ 1.3470302   2.0123408  -0.7764823  -0.49972594]]\n",
            "NumPy Array:\n",
            "[[0.17819056 0.24060718 0.29297762]\n",
            " [0.22062953 0.67330044 0.31739022]]\n",
            "PyTorch Tensor:\n",
            "tensor([[0.1782, 0.2406, 0.2930],\n",
            "        [0.2206, 0.6733, 0.3174]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding the Pytorch Training Pipeline"
      ],
      "metadata": {
        "id": "0tMFwpE0llOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Imports"
      ],
      "metadata": {
        "id": "EwDNvWM6lz-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import torch"
      ],
      "metadata": {
        "id": "ILM1NyXmnxKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Dataset"
      ],
      "metadata": {
        "id": "dVJ29y5qozwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download uciml/breast-cancer-wisconsin-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lWLuMz0oRsD",
        "outputId": "29c4b424-efcc-4bad-e3d3-e3c688d0b2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading breast-cancer-wisconsin-data.zip to /content\n",
            "  0% 0.00/48.6k [00:00<?, ?B/s]\n",
            "100% 48.6k/48.6k [00:00<00:00, 45.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq breast-cancer-wisconsin-data.zip"
      ],
      "metadata": {
        "id": "681UqLEZofDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/data.csv')"
      ],
      "metadata": {
        "id": "oKows6t_oHH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "vgaTc7p9okNo",
        "outputId": "eb228727-7f6d-4ecc-d10e-52bb23b8970c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1a334af-5868-41ab-8b00-ec292c6735de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1a334af-5868-41ab-8b00-ec292c6735de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1a334af-5868-41ab-8b00-ec292c6735de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1a334af-5868-41ab-8b00-ec292c6735de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-20b5d936-7b2b-4fa2-9b0b-a3b775c5ee50\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20b5d936-7b2b-4fa2-9b0b-a3b775c5ee50')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-20b5d936-7b2b-4fa2-9b0b-a3b775c5ee50 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_7VY6fvooDu",
        "outputId": "6666224e-fc51-480b-d6e2-00992335e116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "o9SPhftdoyRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "6UOlLLsAo0i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "9-_XfxsCpMNr",
        "outputId": "ef34d1a3-890c-4b67-c5cf-fe26bf2dd568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0         M        17.99         10.38          122.80     1001.0   \n",
              "1         M        20.57         17.77          132.90     1326.0   \n",
              "2         M        19.69         21.25          130.00     1203.0   \n",
              "3         M        11.42         20.38           77.58      386.1   \n",
              "4         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0         0.2419  ...         25.38          17.33           184.60   \n",
              "1         0.1812  ...         24.99          23.41           158.80   \n",
              "2         0.2069  ...         23.57          25.53           152.50   \n",
              "3         0.2597  ...         14.91          26.50            98.87   \n",
              "4         0.1809  ...         22.54          16.67           152.20   \n",
              "\n",
              "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b90f287-b05a-4e84-b250-fbb9e629912d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b90f287-b05a-4e84-b250-fbb9e629912d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b90f287-b05a-4e84-b250-fbb9e629912d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b90f287-b05a-4e84-b250-fbb9e629912d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-58739d95-cd4c-4e40-ae2b-3f18e6d976c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58739d95-cd4c-4e40-ae2b-3f18e6d976c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-58739d95-cd4c-4e40-ae2b-3f18e6d976c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.drop('diagnosis', axis=1), data['diagnosis'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Dxas9wYopOfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ZlX0owBapdVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "pBLyzi6rpmbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float64)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float64)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "y_test_tensor = torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "uVr9GzXwpoat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_train_tensor)) # For, testing\n",
        "print(type(y_train_tensor))\n",
        "print(type(X_test_tensor))\n",
        "print(type(y_test_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FSW57lGqCSF",
        "outputId": "8aca914a-11ac-46b8-9846-721dd33f85a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "SttTTfoGqJJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN():\n",
        "\n",
        "  def __init__(self, X):\n",
        "    self.weights = torch.rand(X.shape[1], 1, dtype=torch.float64, requires_grad=True)\n",
        "    self.bias = torch.zeros(1, dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "  def forward(self, X):\n",
        "    z = torch.matmul(X, self.weights) + self.bias\n",
        "\n",
        "    return torch.sigmoid(z) # y_pred\n",
        "\n",
        "  def loss_fn(self, y_pred, y):\n",
        "    # Clamping prediction to avoid log(0)\n",
        "    epsilon = 1e-7\n",
        "    y_pred = torch.clamp(y_pred, epsilon, 1-epsilon)\n",
        "\n",
        "    return -torch.mean(y * torch.log(y_pred) + (1-y) * torch.log(1-y_pred)) # loss"
      ],
      "metadata": {
        "id": "pTa0XO24qOXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important Hyper-parameters"
      ],
      "metadata": {
        "id": "B76pbe1WrfN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.1\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "DdxXoOm7rkNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training (Pipeline)"
      ],
      "metadata": {
        "id": "NQKvaHxSro4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN(X_train_tensor)"
      ],
      "metadata": {
        "id": "XHbYoVfnwj5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  # Forward pass\n",
        "  y_pred = model.forward(X_train_tensor)\n",
        "\n",
        "  # Loss Calculation\n",
        "  loss = model.loss_fn(y_pred, y_train_tensor)\n",
        "\n",
        "  # Backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # Updating weights\n",
        "  with torch.no_grad():\n",
        "    model.weights -= lr * model.weights.grad\n",
        "    model.bias -= lr * model.bias.grad\n",
        "\n",
        "  # Zeroing gradients\n",
        "  model.weights.grad.zero_()\n",
        "  model.bias.grad.zero_()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t80-GBlrt1u",
        "outputId": "21dce409-3ed6-4fd0-c1a9-3670a03c3446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 3.1221360960148528\n",
            "Epoch: 2, Loss: 2.9746338239946306\n",
            "Epoch: 3, Loss: 2.8189572207816824\n",
            "Epoch: 4, Loss: 2.655172726781337\n",
            "Epoch: 5, Loss: 2.485839938224061\n",
            "Epoch: 6, Loss: 2.3179844785636754\n",
            "Epoch: 7, Loss: 2.1493499605740274\n",
            "Epoch: 8, Loss: 1.9832522355338689\n",
            "Epoch: 9, Loss: 1.8219434268387005\n",
            "Epoch: 10, Loss: 1.664295642925575\n",
            "Epoch: 11, Loss: 1.5175033487433607\n",
            "Epoch: 12, Loss: 1.3834030021096522\n",
            "Epoch: 13, Loss: 1.2637973877549475\n",
            "Epoch: 14, Loss: 1.1602464904887708\n",
            "Epoch: 15, Loss: 1.0736994980032526\n",
            "Epoch: 16, Loss: 1.0040338415600267\n",
            "Epoch: 17, Loss: 0.9498204151149261\n",
            "Epoch: 18, Loss: 0.9085331413359746\n",
            "Epoch: 19, Loss: 0.8772001679150564\n",
            "Epoch: 20, Loss: 0.8531352283082796\n",
            "Epoch: 21, Loss: 0.8342676943398079\n",
            "Epoch: 22, Loss: 0.8191144306203729\n",
            "Epoch: 23, Loss: 0.8066442851953071\n",
            "Epoch: 24, Loss: 0.7961496501073025\n",
            "Epoch: 25, Loss: 0.7871462406737466\n",
            "Epoch: 26, Loss: 0.7792997545464351\n",
            "Epoch: 27, Loss: 0.7723748469723182\n",
            "Epoch: 28, Loss: 0.7662011925247142\n",
            "Epoch: 29, Loss: 0.7606516386140649\n",
            "Epoch: 30, Loss: 0.755628383573642\n",
            "Epoch: 31, Loss: 0.751054242287156\n",
            "Epoch: 32, Loss: 0.7468670464281987\n",
            "Epoch: 33, Loss: 0.7430159508375613\n",
            "Epoch: 34, Loss: 0.7394589012423743\n",
            "Epoch: 35, Loss: 0.7361608219800269\n",
            "Epoch: 36, Loss: 0.7330922649134726\n",
            "Epoch: 37, Loss: 0.7302283673132196\n",
            "Epoch: 38, Loss: 0.7275480275040114\n",
            "Epoch: 39, Loss: 0.725033241654699\n",
            "Epoch: 40, Loss: 0.7226685647161337\n",
            "Epoch: 41, Loss: 0.7204406698438076\n",
            "Epoch: 42, Loss: 0.7183379874299071\n",
            "Epoch: 43, Loss: 0.7163504091740799\n",
            "Epoch: 44, Loss: 0.7144690455522101\n",
            "Epoch: 45, Loss: 0.7126860271843409\n",
            "Epoch: 46, Loss: 0.7109943422639563\n",
            "Epoch: 47, Loss: 0.709387703552817\n",
            "Epoch: 48, Loss: 0.707860439555969\n",
            "Epoch: 49, Loss: 0.7064074054208421\n",
            "Epoch: 50, Loss: 0.7050239098848031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "DWb1nKe4xARc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_test_tensor)\n",
        "  y_pred = (y_pred > 0.5).float()\n",
        "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
        "\n",
        "  print(f'Accuracy: {accuracy.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CffJETqZxC4I",
        "outputId": "6eab3e6a-7d51-4073-a1a2-cb90b73fd616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5689442753791809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch NN and `torch.optim` Module"
      ],
      "metadata": {
        "id": "45MgVp9hi-Ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The use of the said PyTorch modules will help us in improving the fundamental PyTorch training pipeline by:\n",
        "- Building the neural network using the nn module\n",
        "- Using built-in activation functions\n",
        "- Built-in loss functions\n",
        "- Built-in Optimizers\n"
      ],
      "metadata": {
        "id": "CK3VoT2JlfwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Imports"
      ],
      "metadata": {
        "id": "w8bIJa4XjDKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ],
      "metadata": {
        "id": "9EZjfwchnkrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Dataset\n",
        "\n",
        "**Note:** Here, we just generating a random dataset to simulate the processes"
      ],
      "metadata": {
        "id": "mz4z_LNFo5PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = torch.rand(1000, 5)"
      ],
      "metadata": {
        "id": "PjGMYthwpEeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "P767SI3ynpqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel1(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear = nn.Linear(num_features, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, features):\n",
        "    output = self.linear(features)\n",
        "    output = self.sigmoid(output)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "h8_BxORsnxKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build a more sofisticated model to leverage other PyTorch provided utilities"
      ],
      "metadata": {
        "id": "Zcdhid-nrlZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel2(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear1 = nn.Linear(num_features, 3)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(3, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, features):\n",
        "    output = self.linear1(features)\n",
        "    output = self.relu(output)\n",
        "    output = self.linear2(output)\n",
        "    output = self.sigmoid(output)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "n21yZ88Jrycb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Individually, defining the layers are not considered amoung the best of practices when building deep learning models through PyTorch; therefore, we encapsule the layers within a single sequential module, like:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Within the constructor\n",
        "self.network = nn.Sequential(\n",
        "    nn.Linear(num_features, 3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(3, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Within the forward pass method\n",
        "return self.network(features)\n",
        "```"
      ],
      "metadata": {
        "id": "b3OCysEYtFxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training (Pipeline)"
      ],
      "metadata": {
        "id": "HIa_S-qUn4FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel1(features.shape[1])"
      ],
      "metadata": {
        "id": "RoQhdpxCpTFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(features) # Forward pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-pnAh3_peqB",
        "outputId": "532d7ab4-c5d9-4525-951e-0ace2c98c749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3484],\n",
              "        [0.4229],\n",
              "        [0.4356],\n",
              "        [0.4234],\n",
              "        [0.3726],\n",
              "        [0.3863],\n",
              "        [0.3953],\n",
              "        [0.4213],\n",
              "        [0.3306],\n",
              "        [0.3773],\n",
              "        [0.4033],\n",
              "        [0.3828],\n",
              "        [0.3988],\n",
              "        [0.3934],\n",
              "        [0.4114],\n",
              "        [0.4049],\n",
              "        [0.4666],\n",
              "        [0.3691],\n",
              "        [0.3918],\n",
              "        [0.3603],\n",
              "        [0.3995],\n",
              "        [0.3647],\n",
              "        [0.4382],\n",
              "        [0.3620],\n",
              "        [0.4119],\n",
              "        [0.4113],\n",
              "        [0.4413],\n",
              "        [0.4465],\n",
              "        [0.4098],\n",
              "        [0.3978],\n",
              "        [0.4034],\n",
              "        [0.4257],\n",
              "        [0.3892],\n",
              "        [0.3564],\n",
              "        [0.4149],\n",
              "        [0.4051],\n",
              "        [0.4116],\n",
              "        [0.3133],\n",
              "        [0.4122],\n",
              "        [0.4018],\n",
              "        [0.4389],\n",
              "        [0.4336],\n",
              "        [0.3901],\n",
              "        [0.4149],\n",
              "        [0.4282],\n",
              "        [0.3779],\n",
              "        [0.4243],\n",
              "        [0.4690],\n",
              "        [0.4160],\n",
              "        [0.4011],\n",
              "        [0.3997],\n",
              "        [0.3967],\n",
              "        [0.4347],\n",
              "        [0.4292],\n",
              "        [0.3975],\n",
              "        [0.4553],\n",
              "        [0.4531],\n",
              "        [0.3994],\n",
              "        [0.3901],\n",
              "        [0.4343],\n",
              "        [0.3967],\n",
              "        [0.3553],\n",
              "        [0.4323],\n",
              "        [0.4293],\n",
              "        [0.4427],\n",
              "        [0.3767],\n",
              "        [0.4545],\n",
              "        [0.3542],\n",
              "        [0.3917],\n",
              "        [0.3789],\n",
              "        [0.4565],\n",
              "        [0.3696],\n",
              "        [0.3300],\n",
              "        [0.4343],\n",
              "        [0.3798],\n",
              "        [0.4001],\n",
              "        [0.3966],\n",
              "        [0.4189],\n",
              "        [0.3879],\n",
              "        [0.4212],\n",
              "        [0.3866],\n",
              "        [0.4572],\n",
              "        [0.3414],\n",
              "        [0.4088],\n",
              "        [0.4433],\n",
              "        [0.3664],\n",
              "        [0.4215],\n",
              "        [0.3539],\n",
              "        [0.3918],\n",
              "        [0.3704],\n",
              "        [0.3484],\n",
              "        [0.4391],\n",
              "        [0.4104],\n",
              "        [0.4453],\n",
              "        [0.4289],\n",
              "        [0.3512],\n",
              "        [0.3945],\n",
              "        [0.4622],\n",
              "        [0.4421],\n",
              "        [0.3799],\n",
              "        [0.3696],\n",
              "        [0.4198],\n",
              "        [0.4320],\n",
              "        [0.3803],\n",
              "        [0.3621],\n",
              "        [0.3902],\n",
              "        [0.4019],\n",
              "        [0.3662],\n",
              "        [0.4128],\n",
              "        [0.3804],\n",
              "        [0.3571],\n",
              "        [0.3706],\n",
              "        [0.4033],\n",
              "        [0.4367],\n",
              "        [0.4730],\n",
              "        [0.3368],\n",
              "        [0.3905],\n",
              "        [0.4365],\n",
              "        [0.3705],\n",
              "        [0.3927],\n",
              "        [0.4243],\n",
              "        [0.4267],\n",
              "        [0.3920],\n",
              "        [0.3653],\n",
              "        [0.4529],\n",
              "        [0.3652],\n",
              "        [0.4331],\n",
              "        [0.4167],\n",
              "        [0.4302],\n",
              "        [0.3924],\n",
              "        [0.3854],\n",
              "        [0.4029],\n",
              "        [0.4230],\n",
              "        [0.3680],\n",
              "        [0.4221],\n",
              "        [0.4260],\n",
              "        [0.3737],\n",
              "        [0.4388],\n",
              "        [0.3470],\n",
              "        [0.3712],\n",
              "        [0.3780],\n",
              "        [0.4375],\n",
              "        [0.4196],\n",
              "        [0.4831],\n",
              "        [0.3628],\n",
              "        [0.4446],\n",
              "        [0.4737],\n",
              "        [0.4223],\n",
              "        [0.3586],\n",
              "        [0.3573],\n",
              "        [0.4228],\n",
              "        [0.3922],\n",
              "        [0.4632],\n",
              "        [0.4032],\n",
              "        [0.4005],\n",
              "        [0.3802],\n",
              "        [0.3916],\n",
              "        [0.4499],\n",
              "        [0.4346],\n",
              "        [0.3514],\n",
              "        [0.4377],\n",
              "        [0.4225],\n",
              "        [0.4153],\n",
              "        [0.3976],\n",
              "        [0.3679],\n",
              "        [0.3727],\n",
              "        [0.4779],\n",
              "        [0.3886],\n",
              "        [0.4222],\n",
              "        [0.4623],\n",
              "        [0.3724],\n",
              "        [0.3638],\n",
              "        [0.4103],\n",
              "        [0.3604],\n",
              "        [0.4060],\n",
              "        [0.3977],\n",
              "        [0.3631],\n",
              "        [0.4265],\n",
              "        [0.3206],\n",
              "        [0.4044],\n",
              "        [0.4192],\n",
              "        [0.3968],\n",
              "        [0.3606],\n",
              "        [0.3749],\n",
              "        [0.3809],\n",
              "        [0.3985],\n",
              "        [0.4456],\n",
              "        [0.3649],\n",
              "        [0.3438],\n",
              "        [0.4172],\n",
              "        [0.3554],\n",
              "        [0.3412],\n",
              "        [0.4156],\n",
              "        [0.4422],\n",
              "        [0.3687],\n",
              "        [0.3873],\n",
              "        [0.4161],\n",
              "        [0.3852],\n",
              "        [0.3262],\n",
              "        [0.4235],\n",
              "        [0.4301],\n",
              "        [0.4654],\n",
              "        [0.4077],\n",
              "        [0.4493],\n",
              "        [0.3633],\n",
              "        [0.4342],\n",
              "        [0.4106],\n",
              "        [0.4208],\n",
              "        [0.4259],\n",
              "        [0.4245],\n",
              "        [0.3799],\n",
              "        [0.3747],\n",
              "        [0.3987],\n",
              "        [0.4140],\n",
              "        [0.3361],\n",
              "        [0.4161],\n",
              "        [0.4310],\n",
              "        [0.4578],\n",
              "        [0.3805],\n",
              "        [0.4170],\n",
              "        [0.4233],\n",
              "        [0.3642],\n",
              "        [0.3936],\n",
              "        [0.4055],\n",
              "        [0.4029],\n",
              "        [0.4390],\n",
              "        [0.3996],\n",
              "        [0.4521],\n",
              "        [0.4390],\n",
              "        [0.3987],\n",
              "        [0.3956],\n",
              "        [0.4733],\n",
              "        [0.3761],\n",
              "        [0.3928],\n",
              "        [0.4251],\n",
              "        [0.3968],\n",
              "        [0.4207],\n",
              "        [0.3938],\n",
              "        [0.4434],\n",
              "        [0.4166],\n",
              "        [0.4812],\n",
              "        [0.3900],\n",
              "        [0.3600],\n",
              "        [0.3479],\n",
              "        [0.3593],\n",
              "        [0.4816],\n",
              "        [0.4020],\n",
              "        [0.3644],\n",
              "        [0.3558],\n",
              "        [0.3909],\n",
              "        [0.5034],\n",
              "        [0.4578],\n",
              "        [0.3191],\n",
              "        [0.3652],\n",
              "        [0.4012],\n",
              "        [0.3859],\n",
              "        [0.3533],\n",
              "        [0.4289],\n",
              "        [0.4013],\n",
              "        [0.3439],\n",
              "        [0.4227],\n",
              "        [0.3803],\n",
              "        [0.3806],\n",
              "        [0.4214],\n",
              "        [0.3673],\n",
              "        [0.3845],\n",
              "        [0.3872],\n",
              "        [0.4487],\n",
              "        [0.3914],\n",
              "        [0.4352],\n",
              "        [0.4297],\n",
              "        [0.4170],\n",
              "        [0.3315],\n",
              "        [0.3913],\n",
              "        [0.3988],\n",
              "        [0.3647],\n",
              "        [0.4090],\n",
              "        [0.3819],\n",
              "        [0.3185],\n",
              "        [0.4430],\n",
              "        [0.3626],\n",
              "        [0.3824],\n",
              "        [0.4063],\n",
              "        [0.4243],\n",
              "        [0.3910],\n",
              "        [0.4285],\n",
              "        [0.4052],\n",
              "        [0.3790],\n",
              "        [0.4394],\n",
              "        [0.3589],\n",
              "        [0.4300],\n",
              "        [0.4177],\n",
              "        [0.3796],\n",
              "        [0.3798],\n",
              "        [0.3736],\n",
              "        [0.4086],\n",
              "        [0.3867],\n",
              "        [0.4142],\n",
              "        [0.4820],\n",
              "        [0.4520],\n",
              "        [0.4601],\n",
              "        [0.4174],\n",
              "        [0.3894],\n",
              "        [0.4672],\n",
              "        [0.3679],\n",
              "        [0.4118],\n",
              "        [0.3887],\n",
              "        [0.3975],\n",
              "        [0.4260],\n",
              "        [0.4026],\n",
              "        [0.4478],\n",
              "        [0.4389],\n",
              "        [0.4657],\n",
              "        [0.3681],\n",
              "        [0.4416],\n",
              "        [0.3740],\n",
              "        [0.3622],\n",
              "        [0.4073],\n",
              "        [0.3611],\n",
              "        [0.3930],\n",
              "        [0.4081],\n",
              "        [0.4046],\n",
              "        [0.3222],\n",
              "        [0.4393],\n",
              "        [0.3487],\n",
              "        [0.4227],\n",
              "        [0.4076],\n",
              "        [0.3723],\n",
              "        [0.3497],\n",
              "        [0.3740],\n",
              "        [0.3303],\n",
              "        [0.3857],\n",
              "        [0.3951],\n",
              "        [0.3613],\n",
              "        [0.3823],\n",
              "        [0.3589],\n",
              "        [0.4306],\n",
              "        [0.4838],\n",
              "        [0.4297],\n",
              "        [0.3491],\n",
              "        [0.4000],\n",
              "        [0.4643],\n",
              "        [0.4196],\n",
              "        [0.3898],\n",
              "        [0.4299],\n",
              "        [0.3921],\n",
              "        [0.3428],\n",
              "        [0.4056],\n",
              "        [0.4136],\n",
              "        [0.3856],\n",
              "        [0.4587],\n",
              "        [0.4168],\n",
              "        [0.3973],\n",
              "        [0.3981],\n",
              "        [0.3794],\n",
              "        [0.3595],\n",
              "        [0.3829],\n",
              "        [0.3759],\n",
              "        [0.4007],\n",
              "        [0.4254],\n",
              "        [0.3579],\n",
              "        [0.3648],\n",
              "        [0.3551],\n",
              "        [0.4364],\n",
              "        [0.3571],\n",
              "        [0.4275],\n",
              "        [0.3781],\n",
              "        [0.3857],\n",
              "        [0.4086],\n",
              "        [0.3927],\n",
              "        [0.4126],\n",
              "        [0.3784],\n",
              "        [0.4060],\n",
              "        [0.3675],\n",
              "        [0.3588],\n",
              "        [0.4254],\n",
              "        [0.3935],\n",
              "        [0.4205],\n",
              "        [0.3556],\n",
              "        [0.4054],\n",
              "        [0.4304],\n",
              "        [0.4168],\n",
              "        [0.4146],\n",
              "        [0.3948],\n",
              "        [0.4034],\n",
              "        [0.3992],\n",
              "        [0.4096],\n",
              "        [0.4656],\n",
              "        [0.4531],\n",
              "        [0.4313],\n",
              "        [0.4385],\n",
              "        [0.3624],\n",
              "        [0.4258],\n",
              "        [0.3906],\n",
              "        [0.3722],\n",
              "        [0.4785],\n",
              "        [0.3731],\n",
              "        [0.4273],\n",
              "        [0.4421],\n",
              "        [0.4122],\n",
              "        [0.3854],\n",
              "        [0.3904],\n",
              "        [0.4827],\n",
              "        [0.4363],\n",
              "        [0.3617],\n",
              "        [0.4416],\n",
              "        [0.4097],\n",
              "        [0.4267],\n",
              "        [0.4007],\n",
              "        [0.3862],\n",
              "        [0.3806],\n",
              "        [0.4325],\n",
              "        [0.3985],\n",
              "        [0.3828],\n",
              "        [0.4173],\n",
              "        [0.4160],\n",
              "        [0.4463],\n",
              "        [0.3724],\n",
              "        [0.3758],\n",
              "        [0.4164],\n",
              "        [0.3975],\n",
              "        [0.4273],\n",
              "        [0.4417],\n",
              "        [0.3650],\n",
              "        [0.4004],\n",
              "        [0.3829],\n",
              "        [0.4704],\n",
              "        [0.4242],\n",
              "        [0.4831],\n",
              "        [0.4083],\n",
              "        [0.4356],\n",
              "        [0.4112],\n",
              "        [0.3904],\n",
              "        [0.3669],\n",
              "        [0.4278],\n",
              "        [0.4507],\n",
              "        [0.4215],\n",
              "        [0.3762],\n",
              "        [0.3746],\n",
              "        [0.4228],\n",
              "        [0.4416],\n",
              "        [0.3667],\n",
              "        [0.3986],\n",
              "        [0.4136],\n",
              "        [0.4353],\n",
              "        [0.4052],\n",
              "        [0.3797],\n",
              "        [0.3882],\n",
              "        [0.3641],\n",
              "        [0.3509],\n",
              "        [0.3660],\n",
              "        [0.3311],\n",
              "        [0.3758],\n",
              "        [0.3774],\n",
              "        [0.4017],\n",
              "        [0.3801],\n",
              "        [0.3683],\n",
              "        [0.3819],\n",
              "        [0.3907],\n",
              "        [0.3176],\n",
              "        [0.4770],\n",
              "        [0.3687],\n",
              "        [0.4368],\n",
              "        [0.3601],\n",
              "        [0.4100],\n",
              "        [0.4145],\n",
              "        [0.4596],\n",
              "        [0.4290],\n",
              "        [0.4122],\n",
              "        [0.3994],\n",
              "        [0.4198],\n",
              "        [0.3999],\n",
              "        [0.4103],\n",
              "        [0.3383],\n",
              "        [0.3828],\n",
              "        [0.3636],\n",
              "        [0.4067],\n",
              "        [0.4110],\n",
              "        [0.3814],\n",
              "        [0.3807],\n",
              "        [0.3567],\n",
              "        [0.3906],\n",
              "        [0.3718],\n",
              "        [0.3345],\n",
              "        [0.3723],\n",
              "        [0.4129],\n",
              "        [0.3845],\n",
              "        [0.4205],\n",
              "        [0.4588],\n",
              "        [0.3865],\n",
              "        [0.3809],\n",
              "        [0.3843],\n",
              "        [0.3200],\n",
              "        [0.3987],\n",
              "        [0.3899],\n",
              "        [0.4224],\n",
              "        [0.3711],\n",
              "        [0.4196],\n",
              "        [0.4183],\n",
              "        [0.4385],\n",
              "        [0.3993],\n",
              "        [0.4069],\n",
              "        [0.3954],\n",
              "        [0.4042],\n",
              "        [0.4232],\n",
              "        [0.3824],\n",
              "        [0.3942],\n",
              "        [0.3816],\n",
              "        [0.4155],\n",
              "        [0.3613],\n",
              "        [0.4773],\n",
              "        [0.3691],\n",
              "        [0.4213],\n",
              "        [0.4215],\n",
              "        [0.3642],\n",
              "        [0.3884],\n",
              "        [0.4150],\n",
              "        [0.4085],\n",
              "        [0.3677],\n",
              "        [0.3820],\n",
              "        [0.3922],\n",
              "        [0.4066],\n",
              "        [0.4946],\n",
              "        [0.4049],\n",
              "        [0.4423],\n",
              "        [0.3801],\n",
              "        [0.3592],\n",
              "        [0.3685],\n",
              "        [0.4451],\n",
              "        [0.4264],\n",
              "        [0.3720],\n",
              "        [0.3537],\n",
              "        [0.4470],\n",
              "        [0.4207],\n",
              "        [0.3945],\n",
              "        [0.4306],\n",
              "        [0.4007],\n",
              "        [0.4289],\n",
              "        [0.3989],\n",
              "        [0.3748],\n",
              "        [0.3517],\n",
              "        [0.4002],\n",
              "        [0.4164],\n",
              "        [0.4010],\n",
              "        [0.4536],\n",
              "        [0.3896],\n",
              "        [0.4498],\n",
              "        [0.3605],\n",
              "        [0.3971],\n",
              "        [0.3133],\n",
              "        [0.4025],\n",
              "        [0.4260],\n",
              "        [0.3613],\n",
              "        [0.3747],\n",
              "        [0.4050],\n",
              "        [0.3485],\n",
              "        [0.3399],\n",
              "        [0.4364],\n",
              "        [0.4160],\n",
              "        [0.4202],\n",
              "        [0.3853],\n",
              "        [0.3401],\n",
              "        [0.4695],\n",
              "        [0.3455],\n",
              "        [0.4277],\n",
              "        [0.4196],\n",
              "        [0.4034],\n",
              "        [0.4036],\n",
              "        [0.3943],\n",
              "        [0.4412],\n",
              "        [0.3209],\n",
              "        [0.3796],\n",
              "        [0.3451],\n",
              "        [0.3989],\n",
              "        [0.4083],\n",
              "        [0.4477],\n",
              "        [0.4158],\n",
              "        [0.3919],\n",
              "        [0.4211],\n",
              "        [0.4168],\n",
              "        [0.3716],\n",
              "        [0.3510],\n",
              "        [0.4071],\n",
              "        [0.4313],\n",
              "        [0.3845],\n",
              "        [0.3930],\n",
              "        [0.3884],\n",
              "        [0.4278],\n",
              "        [0.4324],\n",
              "        [0.3936],\n",
              "        [0.3438],\n",
              "        [0.4198],\n",
              "        [0.3680],\n",
              "        [0.3876],\n",
              "        [0.4624],\n",
              "        [0.4594],\n",
              "        [0.3676],\n",
              "        [0.4637],\n",
              "        [0.3650],\n",
              "        [0.4752],\n",
              "        [0.4317],\n",
              "        [0.4193],\n",
              "        [0.4193],\n",
              "        [0.4055],\n",
              "        [0.4141],\n",
              "        [0.3417],\n",
              "        [0.3798],\n",
              "        [0.3794],\n",
              "        [0.4238],\n",
              "        [0.3665],\n",
              "        [0.3902],\n",
              "        [0.4256],\n",
              "        [0.4225],\n",
              "        [0.4250],\n",
              "        [0.3884],\n",
              "        [0.4068],\n",
              "        [0.3864],\n",
              "        [0.3872],\n",
              "        [0.3552],\n",
              "        [0.3544],\n",
              "        [0.3687],\n",
              "        [0.3731],\n",
              "        [0.4523],\n",
              "        [0.3753],\n",
              "        [0.3403],\n",
              "        [0.3341],\n",
              "        [0.4524],\n",
              "        [0.3797],\n",
              "        [0.4488],\n",
              "        [0.4398],\n",
              "        [0.4012],\n",
              "        [0.4944],\n",
              "        [0.4308],\n",
              "        [0.4730],\n",
              "        [0.4180],\n",
              "        [0.4268],\n",
              "        [0.4195],\n",
              "        [0.4110],\n",
              "        [0.4037],\n",
              "        [0.4116],\n",
              "        [0.4640],\n",
              "        [0.4286],\n",
              "        [0.4069],\n",
              "        [0.3599],\n",
              "        [0.3456],\n",
              "        [0.3700],\n",
              "        [0.4163],\n",
              "        [0.4398],\n",
              "        [0.4259],\n",
              "        [0.3947],\n",
              "        [0.4231],\n",
              "        [0.3938],\n",
              "        [0.4443],\n",
              "        [0.4027],\n",
              "        [0.4265],\n",
              "        [0.3724],\n",
              "        [0.4345],\n",
              "        [0.4133],\n",
              "        [0.4431],\n",
              "        [0.3581],\n",
              "        [0.3975],\n",
              "        [0.3841],\n",
              "        [0.4018],\n",
              "        [0.4199],\n",
              "        [0.3597],\n",
              "        [0.3874],\n",
              "        [0.3774],\n",
              "        [0.3909],\n",
              "        [0.4088],\n",
              "        [0.4428],\n",
              "        [0.3313],\n",
              "        [0.3763],\n",
              "        [0.3436],\n",
              "        [0.3963],\n",
              "        [0.4219],\n",
              "        [0.3670],\n",
              "        [0.3558],\n",
              "        [0.4499],\n",
              "        [0.3919],\n",
              "        [0.4186],\n",
              "        [0.4322],\n",
              "        [0.3846],\n",
              "        [0.3673],\n",
              "        [0.3734],\n",
              "        [0.3823],\n",
              "        [0.4199],\n",
              "        [0.3966],\n",
              "        [0.3698],\n",
              "        [0.4012],\n",
              "        [0.4880],\n",
              "        [0.3710],\n",
              "        [0.3957],\n",
              "        [0.4119],\n",
              "        [0.3408],\n",
              "        [0.3779],\n",
              "        [0.3967],\n",
              "        [0.4002],\n",
              "        [0.3891],\n",
              "        [0.4255],\n",
              "        [0.4408],\n",
              "        [0.5024],\n",
              "        [0.4352],\n",
              "        [0.3337],\n",
              "        [0.3541],\n",
              "        [0.3901],\n",
              "        [0.4384],\n",
              "        [0.4081],\n",
              "        [0.3989],\n",
              "        [0.4448],\n",
              "        [0.4569],\n",
              "        [0.3143],\n",
              "        [0.4262],\n",
              "        [0.4554],\n",
              "        [0.4054],\n",
              "        [0.4752],\n",
              "        [0.3660],\n",
              "        [0.4733],\n",
              "        [0.4233],\n",
              "        [0.3630],\n",
              "        [0.3769],\n",
              "        [0.3923],\n",
              "        [0.3569],\n",
              "        [0.4467],\n",
              "        [0.4090],\n",
              "        [0.3720],\n",
              "        [0.3932],\n",
              "        [0.3780],\n",
              "        [0.3697],\n",
              "        [0.3868],\n",
              "        [0.4004],\n",
              "        [0.3951],\n",
              "        [0.3848],\n",
              "        [0.4123],\n",
              "        [0.4370],\n",
              "        [0.3783],\n",
              "        [0.3845],\n",
              "        [0.4489],\n",
              "        [0.4074],\n",
              "        [0.4283],\n",
              "        [0.3748],\n",
              "        [0.3568],\n",
              "        [0.3963],\n",
              "        [0.3922],\n",
              "        [0.4227],\n",
              "        [0.3952],\n",
              "        [0.3959],\n",
              "        [0.3540],\n",
              "        [0.3461],\n",
              "        [0.3633],\n",
              "        [0.3806],\n",
              "        [0.3733],\n",
              "        [0.3655],\n",
              "        [0.3892],\n",
              "        [0.3434],\n",
              "        [0.3772],\n",
              "        [0.3601],\n",
              "        [0.3975],\n",
              "        [0.4102],\n",
              "        [0.4054],\n",
              "        [0.4408],\n",
              "        [0.3959],\n",
              "        [0.4127],\n",
              "        [0.3242],\n",
              "        [0.3862],\n",
              "        [0.4241],\n",
              "        [0.4479],\n",
              "        [0.4051],\n",
              "        [0.3563],\n",
              "        [0.3662],\n",
              "        [0.3582],\n",
              "        [0.3243],\n",
              "        [0.4192],\n",
              "        [0.4057],\n",
              "        [0.3615],\n",
              "        [0.4232],\n",
              "        [0.4042],\n",
              "        [0.4199],\n",
              "        [0.3163],\n",
              "        [0.4291],\n",
              "        [0.4238],\n",
              "        [0.3900],\n",
              "        [0.3782],\n",
              "        [0.4621],\n",
              "        [0.4063],\n",
              "        [0.4386],\n",
              "        [0.3750],\n",
              "        [0.3490],\n",
              "        [0.4568],\n",
              "        [0.3896],\n",
              "        [0.4365],\n",
              "        [0.4090],\n",
              "        [0.4378],\n",
              "        [0.4095],\n",
              "        [0.4368],\n",
              "        [0.4283],\n",
              "        [0.3737],\n",
              "        [0.3733],\n",
              "        [0.3965],\n",
              "        [0.3505],\n",
              "        [0.3788],\n",
              "        [0.3668],\n",
              "        [0.4055],\n",
              "        [0.3882],\n",
              "        [0.4656],\n",
              "        [0.3811],\n",
              "        [0.4583],\n",
              "        [0.3677],\n",
              "        [0.3808],\n",
              "        [0.3200],\n",
              "        [0.4450],\n",
              "        [0.4576],\n",
              "        [0.4205],\n",
              "        [0.4150],\n",
              "        [0.4089],\n",
              "        [0.4301],\n",
              "        [0.4414],\n",
              "        [0.3835],\n",
              "        [0.3896],\n",
              "        [0.3813],\n",
              "        [0.4889],\n",
              "        [0.4055],\n",
              "        [0.3976],\n",
              "        [0.4484],\n",
              "        [0.3640],\n",
              "        [0.4184],\n",
              "        [0.3624],\n",
              "        [0.3848],\n",
              "        [0.3433],\n",
              "        [0.4287],\n",
              "        [0.3643],\n",
              "        [0.4369],\n",
              "        [0.4406],\n",
              "        [0.4262],\n",
              "        [0.3732],\n",
              "        [0.3226],\n",
              "        [0.3794],\n",
              "        [0.3431],\n",
              "        [0.4052],\n",
              "        [0.4564],\n",
              "        [0.4423],\n",
              "        [0.4149],\n",
              "        [0.3954],\n",
              "        [0.4005],\n",
              "        [0.4146],\n",
              "        [0.4642],\n",
              "        [0.4109],\n",
              "        [0.4754],\n",
              "        [0.4011],\n",
              "        [0.4374],\n",
              "        [0.3733],\n",
              "        [0.4553],\n",
              "        [0.3747],\n",
              "        [0.3517],\n",
              "        [0.4560],\n",
              "        [0.3869],\n",
              "        [0.4145],\n",
              "        [0.4679],\n",
              "        [0.3484],\n",
              "        [0.4715],\n",
              "        [0.4729],\n",
              "        [0.3989],\n",
              "        [0.4319],\n",
              "        [0.3401],\n",
              "        [0.4016],\n",
              "        [0.4541],\n",
              "        [0.4003],\n",
              "        [0.4522],\n",
              "        [0.4002],\n",
              "        [0.3565],\n",
              "        [0.3137],\n",
              "        [0.4059],\n",
              "        [0.4636],\n",
              "        [0.3449],\n",
              "        [0.4066],\n",
              "        [0.3970],\n",
              "        [0.3397],\n",
              "        [0.3630],\n",
              "        [0.4049],\n",
              "        [0.3815],\n",
              "        [0.3703],\n",
              "        [0.3800],\n",
              "        [0.4301],\n",
              "        [0.5068],\n",
              "        [0.3879],\n",
              "        [0.3976],\n",
              "        [0.4036],\n",
              "        [0.4054],\n",
              "        [0.3296],\n",
              "        [0.3775],\n",
              "        [0.4857],\n",
              "        [0.3615],\n",
              "        [0.4367],\n",
              "        [0.4715],\n",
              "        [0.4432],\n",
              "        [0.3527],\n",
              "        [0.4193],\n",
              "        [0.3589],\n",
              "        [0.3668],\n",
              "        [0.3391],\n",
              "        [0.4587],\n",
              "        [0.3834],\n",
              "        [0.3815],\n",
              "        [0.4142],\n",
              "        [0.3716],\n",
              "        [0.3964],\n",
              "        [0.4363],\n",
              "        [0.4524],\n",
              "        [0.3809],\n",
              "        [0.4217],\n",
              "        [0.3832],\n",
              "        [0.4293],\n",
              "        [0.3683],\n",
              "        [0.4332],\n",
              "        [0.3792],\n",
              "        [0.4034],\n",
              "        [0.4089],\n",
              "        [0.4425],\n",
              "        [0.4483],\n",
              "        [0.4308],\n",
              "        [0.4600],\n",
              "        [0.4022],\n",
              "        [0.4323],\n",
              "        [0.4232],\n",
              "        [0.4589],\n",
              "        [0.3244],\n",
              "        [0.3749],\n",
              "        [0.4516],\n",
              "        [0.4063],\n",
              "        [0.4019],\n",
              "        [0.4288],\n",
              "        [0.4028],\n",
              "        [0.4075],\n",
              "        [0.4552],\n",
              "        [0.3345],\n",
              "        [0.4119],\n",
              "        [0.4700],\n",
              "        [0.3899],\n",
              "        [0.4007],\n",
              "        [0.3938],\n",
              "        [0.4507],\n",
              "        [0.3657],\n",
              "        [0.4710],\n",
              "        [0.4535],\n",
              "        [0.3390],\n",
              "        [0.4878],\n",
              "        [0.3890],\n",
              "        [0.3364],\n",
              "        [0.3661],\n",
              "        [0.3988],\n",
              "        [0.3927],\n",
              "        [0.4572],\n",
              "        [0.4800],\n",
              "        [0.4358],\n",
              "        [0.3907],\n",
              "        [0.3675],\n",
              "        [0.4054],\n",
              "        [0.4265],\n",
              "        [0.3646],\n",
              "        [0.4161],\n",
              "        [0.4557],\n",
              "        [0.4732],\n",
              "        [0.4019],\n",
              "        [0.3979],\n",
              "        [0.4333],\n",
              "        [0.3687],\n",
              "        [0.3457],\n",
              "        [0.3783],\n",
              "        [0.3609],\n",
              "        [0.3670],\n",
              "        [0.3757],\n",
              "        [0.3505],\n",
              "        [0.4277],\n",
              "        [0.4236],\n",
              "        [0.3941],\n",
              "        [0.4110],\n",
              "        [0.4320],\n",
              "        [0.3920],\n",
              "        [0.4225],\n",
              "        [0.4484],\n",
              "        [0.3745],\n",
              "        [0.3738],\n",
              "        [0.3996],\n",
              "        [0.4286],\n",
              "        [0.3678],\n",
              "        [0.4271],\n",
              "        [0.4434],\n",
              "        [0.3927],\n",
              "        [0.4645],\n",
              "        [0.4155],\n",
              "        [0.3873],\n",
              "        [0.3998],\n",
              "        [0.3744],\n",
              "        [0.4293],\n",
              "        [0.4292],\n",
              "        [0.4191],\n",
              "        [0.4107],\n",
              "        [0.4415],\n",
              "        [0.4134],\n",
              "        [0.4205],\n",
              "        [0.3724]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The reason is that we are not calling the forward function the traditional way is that, within the core pytorch module (from which the inheritence has been made), has overriden the `__call__()` magic function."
      ],
      "metadata": {
        "id": "hBat58TNp4eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.linear.weight)\n",
        "print(model.linear.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9LmYBawqKhM",
        "outputId": "c82c085e-54f9-4303-e544-260eb0fdac14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.2996, -0.2684,  0.0810, -0.3107,  0.0780]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.3437], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to get a summary of your model; do the following"
      ],
      "metadata": {
        "id": "GVsMuM-IqwuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4B6Eh4IrSog",
        "outputId": "2590d565-a28f-429c-bf4c-b86e5e4ca665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model, input_size=(1000, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-ghnsE3rCxk",
        "outputId": "42342835-37d0-485e-d186-06d105b46768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "SimpleModel1                             [1000, 1]                 --\n",
              "├─Linear: 1-1                            [1000, 1]                 6\n",
              "├─Sigmoid: 1-2                           [1000, 1]                 --\n",
              "==========================================================================================\n",
              "Total params: 6\n",
              "Trainable params: 6\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.01\n",
              "==========================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 0.01\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.03\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training (Pipeline) for the more sophisticated model\n",
        "model = SimpleModel2(features.shape[1])\n",
        "\n",
        "model(features) # Forward pass\n",
        "\n",
        "print(model.linear1.weight)\n",
        "print(model.linear1.bias)\n",
        "print(model.linear2.weight)\n",
        "print(model.linear2.bias)\n",
        "print()\n",
        "\n",
        "print(\"Summary:\")\n",
        "summary(model, input_size=(1000, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFm7QlPbsOR-",
        "outputId": "ea3dc478-3bc2-4a58-ce40-ac78cb06f549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3217,  0.3939, -0.2001,  0.3666,  0.1902],\n",
            "        [-0.0878, -0.3509,  0.0813,  0.3021,  0.2419],\n",
            "        [ 0.1969,  0.3344,  0.1038,  0.2941, -0.3094]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1663,  0.3343,  0.2039], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.3705, -0.0688,  0.3127]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1975], requires_grad=True)\n",
            "\n",
            "Summary:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "SimpleModel2                             [1000, 1]                 --\n",
              "├─Linear: 1-1                            [1000, 3]                 18\n",
              "├─ReLU: 1-2                              [1000, 3]                 --\n",
              "├─Linear: 1-3                            [1000, 1]                 4\n",
              "├─Sigmoid: 1-4                           [1000, 1]                 --\n",
              "==========================================================================================\n",
              "Total params: 22\n",
              "Trainable params: 22\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.02\n",
              "==========================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 0.03\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.05\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now, imporving the previously developed architecture"
      ],
      "metadata": {
        "id": "At73sqt4uKZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup and Imports"
      ],
      "metadata": {
        "id": "SYdP0ssuuaIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "Xns8-JmRuaIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the Dataset"
      ],
      "metadata": {
        "id": "RqAqZQXpuaIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download uciml/breast-cancer-wisconsin-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff15338-03ed-43f4-a603-41393adafcdc",
        "id": "UfbLgbaWuaIb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "breast-cancer-wisconsin-data.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq breast-cancer-wisconsin-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eRprBdhuaIb",
        "outputId": "cc8da040-9a6b-4a9f-9dd5-c7baa1f17a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/data.csv')"
      ],
      "metadata": {
        "id": "y5wJ03SNuaIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "14dd79a4-4061-4368-896e-f4429184541d",
        "id": "16W7GWmSuaIc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58d2de70-47f2-468b-87fa-b11fe6550a3b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58d2de70-47f2-468b-87fa-b11fe6550a3b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58d2de70-47f2-468b-87fa-b11fe6550a3b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58d2de70-47f2-468b-87fa-b11fe6550a3b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-21a116ff-7922-4dbf-b0a9-3615667bc85a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21a116ff-7922-4dbf-b0a9-3615667bc85a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-21a116ff-7922-4dbf-b0a9-3615667bc85a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad51526-c072-4044-a836-2b8a35e906c0",
        "id": "PDqDV5UyuaIc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Preprocessing"
      ],
      "metadata": {
        "id": "wfNmb5uGuaIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "SyWPO5pauaIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "44202220-762b-4186-b391-44227e12f566",
        "id": "c2le8FQsuaIc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0         M        17.99         10.38          122.80     1001.0   \n",
              "1         M        20.57         17.77          132.90     1326.0   \n",
              "2         M        19.69         21.25          130.00     1203.0   \n",
              "3         M        11.42         20.38           77.58      386.1   \n",
              "4         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0         0.2419  ...         25.38          17.33           184.60   \n",
              "1         0.1812  ...         24.99          23.41           158.80   \n",
              "2         0.2069  ...         23.57          25.53           152.50   \n",
              "3         0.2597  ...         14.91          26.50            98.87   \n",
              "4         0.1809  ...         22.54          16.67           152.20   \n",
              "\n",
              "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-256836e4-7275-4296-9f4e-b1313720134a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-256836e4-7275-4296-9f4e-b1313720134a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-256836e4-7275-4296-9f4e-b1313720134a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-256836e4-7275-4296-9f4e-b1313720134a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ad47a1f-4e19-4367-bfc7-66a93783c53c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ad47a1f-4e19-4367-bfc7-66a93783c53c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ad47a1f-4e19-4367-bfc7-66a93783c53c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.drop('diagnosis', axis=1), data['diagnosis'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "78duDI_LuaIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "CF5AMlk6uaId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "0pfWINasuaId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "fYpUN3hHuaId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_train_tensor)) # For, testing\n",
        "print(type(y_train_tensor))\n",
        "print(type(X_test_tensor))\n",
        "print(type(y_test_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cd5238-f074-4fb6-d112-9365d900ee96",
        "id": "Ygeuq2dsuaId"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Architecture"
      ],
      "metadata": {
        "id": "G6NiN6fKuaId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN1(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.neural_network = nn.Sequential(\n",
        "      nn.Linear(num_features, 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.neural_network(X) # y_pred\n",
        "\n",
        "  # def loss_fn(self, y_pred, y):\n",
        "  #   # Clamping prediction to avoid log(0)\n",
        "  #   epsilon = 1e-7\n",
        "  #   y_pred = torch.clamp(y_pred, epsilon, 1-epsilon)\n",
        "\n",
        "  #   return -torch.mean(y * torch.log(y_pred) + (1-y) * torch.log(1-y_pred)) # loss"
      ],
      "metadata": {
        "id": "fUrur1MXuaIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.BCELoss()"
      ],
      "metadata": {
        "id": "mFNkFFeaw0Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Important Hyper-parameters"
      ],
      "metadata": {
        "id": "4PCYsJBXuaIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.1\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "S5d60ZiTuaIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training (Pipeline)"
      ],
      "metadata": {
        "id": "oXB1rlTNuaIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN1(X_train_tensor.shape[1])\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)  # Here, model.parameters() is an iterator that loops through all of the involved parameter present within the network"
      ],
      "metadata": {
        "id": "NiDcXRofuaIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  # Forward pass\n",
        "  y_pred = model(X_train_tensor)\n",
        "\n",
        "  # Loss Calculation\n",
        "  loss = loss_function(y_pred, y_train_tensor.view(-1, 1))\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # # Updating weights\n",
        "  # with torch.no_grad():\n",
        "  #   model.linear.weights -= lr * model.linear.weight.grad\n",
        "  #   model.linear.bias -= lr * model.linear.bias.grad\n",
        "\n",
        "  # # Zeroing gradients\n",
        "  # model.linear.weights.grad.zero_()\n",
        "  # model.linear.bias.grad.zero_()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e3ef00-d1e0-4f2e-d0da-213e37e23b3f",
        "id": "Fs3AgY9cuaIf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.9145975708961487\n",
            "Epoch: 2, Loss: 0.6562520861625671\n",
            "Epoch: 3, Loss: 0.5155688524246216\n",
            "Epoch: 4, Loss: 0.4359382688999176\n",
            "Epoch: 5, Loss: 0.38459667563438416\n",
            "Epoch: 6, Loss: 0.3482820689678192\n",
            "Epoch: 7, Loss: 0.32098859548568726\n",
            "Epoch: 8, Loss: 0.29958412051200867\n",
            "Epoch: 9, Loss: 0.28226158022880554\n",
            "Epoch: 10, Loss: 0.2678986191749573\n",
            "Epoch: 11, Loss: 0.2557583451271057\n",
            "Epoch: 12, Loss: 0.2453346848487854\n",
            "Epoch: 13, Loss: 0.23626773059368134\n",
            "Epoch: 14, Loss: 0.22829383611679077\n",
            "Epoch: 15, Loss: 0.2212149053812027\n",
            "Epoch: 16, Loss: 0.21487906575202942\n",
            "Epoch: 17, Loss: 0.2091677188873291\n",
            "Epoch: 18, Loss: 0.20398671925067902\n",
            "Epoch: 19, Loss: 0.19926045835018158\n",
            "Epoch: 20, Loss: 0.19492729008197784\n",
            "Epoch: 21, Loss: 0.19093644618988037\n",
            "Epoch: 22, Loss: 0.1872459203004837\n",
            "Epoch: 23, Loss: 0.18382033705711365\n",
            "Epoch: 24, Loss: 0.18062976002693176\n",
            "Epoch: 25, Loss: 0.17764882743358612\n",
            "Epoch: 26, Loss: 0.1748557686805725\n",
            "Epoch: 27, Loss: 0.1722317934036255\n",
            "Epoch: 28, Loss: 0.1697605699300766\n",
            "Epoch: 29, Loss: 0.16742797195911407\n",
            "Epoch: 30, Loss: 0.16522152721881866\n",
            "Epoch: 31, Loss: 0.1631302684545517\n",
            "Epoch: 32, Loss: 0.16114453971385956\n",
            "Epoch: 33, Loss: 0.1592557579278946\n",
            "Epoch: 34, Loss: 0.15745626389980316\n",
            "Epoch: 35, Loss: 0.15573923289775848\n",
            "Epoch: 36, Loss: 0.1540985256433487\n",
            "Epoch: 37, Loss: 0.15252864360809326\n",
            "Epoch: 38, Loss: 0.15102462470531464\n",
            "Epoch: 39, Loss: 0.1495819091796875\n",
            "Epoch: 40, Loss: 0.14819647371768951\n",
            "Epoch: 41, Loss: 0.14686459302902222\n",
            "Epoch: 42, Loss: 0.14558285474777222\n",
            "Epoch: 43, Loss: 0.1443481743335724\n",
            "Epoch: 44, Loss: 0.1431577056646347\n",
            "Epoch: 45, Loss: 0.14200888574123383\n",
            "Epoch: 46, Loss: 0.14089928567409515\n",
            "Epoch: 47, Loss: 0.1398267149925232\n",
            "Epoch: 48, Loss: 0.13878914713859558\n",
            "Epoch: 49, Loss: 0.1377846896648407\n",
            "Epoch: 50, Loss: 0.13681155443191528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "pnEGfGPTuaIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_test_tensor)\n",
        "  y_pred = (y_pred > 0.5).float()\n",
        "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
        "\n",
        "  print(f'Accuracy: {accuracy.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b482d6-d3c4-4dce-b453-0c3248659b47",
        "id": "yzs_aGMquaIf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5301631093025208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building an ANN Using Pytorch"
      ],
      "metadata": {
        "id": "hCSlOuBV8MFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Imports"
      ],
      "metadata": {
        "id": "_WYx9nrn8Qhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset"
      ],
      "metadata": {
        "id": "J9oLM6gJ8VrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t94O8u1E8xiy",
        "outputId": "126d8bbb-3237-4135-9048-487f9162e839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d9637962890>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Data"
      ],
      "metadata": {
        "id": "MAWf3Apf8riV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download zalando-research/fashionmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13qMFiJe8ukH",
        "outputId": "58e075db-8bbd-4773-efa5-520e2f22cdb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
            "License(s): other\n",
            "Downloading fashionmnist.zip to /content\n",
            " 99% 68.0M/68.8M [00:00<00:00, 162MB/s]\n",
            "100% 68.8M/68.8M [00:00<00:00, 148MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq fashionmnist.zip"
      ],
      "metadata": {
        "id": "JCSmScd59Xym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/fashion-mnist_train.csv')"
      ],
      "metadata": {
        "id": "VfYEDEH99chO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-haXvyB49jIt",
        "outputId": "bd093ebf-5048-4a01-f366-00897141c1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      2       0       0       0       0       0       0       0       0   \n",
              "1      9       0       0       0       0       0       0       0       0   \n",
              "2      6       0       0       0       0       0       0       0       5   \n",
              "3      0       0       0       0       1       2       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       0  ...         0         0         0         0         0         0   \n",
              "1       0  ...         0         0         0         0         0         0   \n",
              "2       0  ...         0         0         0        30        43         0   \n",
              "3       0  ...         3         0         0         0         0         1   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e37c31b1-d3f9-4e33-a648-879a95b556a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e37c31b1-d3f9-4e33-a648-879a95b556a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e37c31b1-d3f9-4e33-a648-879a95b556a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e37c31b1-d3f9-4e33-a648-879a95b556a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e880a1d-afd9-4fc2-8a9f-d93f5423f5b0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e880a1d-afd9-4fc2-8a9f-d93f5423f5b0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e880a1d-afd9-4fc2-8a9f-d93f5423f5b0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "8pqEZvQf9mL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 1:].values\n",
        "y = data.iloc[:, 0].values"
      ],
      "metadata": {
        "id": "rlLj3d4Y9v5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zzsOqw1293aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "wy_cXz6j98oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, labels):\n",
        "    self.features = torch.tensor(features, dtype=torch.float32)\n",
        "    self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.features[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "BlQVvDgm-Eum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "test_dataset = CustomDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "sZih9K9_LhD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "HDqLiotFL-XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "_--rTlcFMJjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(num_features, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.model(X)"
      ],
      "metadata": {
        "id": "ZhmftGA8MEJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important hyperparameters"
      ],
      "metadata": {
        "id": "NM-1wWcGr4EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "8ArONVbWNMVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training (Pipeline)"
      ],
      "metadata": {
        "id": "mMeCFH0CNJml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(X_train.shape[1])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "Le31tGtYNVNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_epoch_loss = 0\n",
        "\n",
        "  for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "\n",
        "    y_pred = model(features)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = criterion(y_pred, labels)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Average Epoch Loss: {total_epoch_loss/len(train_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7TqFNGPNsLw",
        "outputId": "7c40e4cc-ac09-4704-ae5f-2ed4735aaf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Average Epoch Loss: 2.2953363132476805\n",
            "Epoch: 2, Average Epoch Loss: 2.2953363134066262\n",
            "Epoch: 3, Average Epoch Loss: 2.2953363089561463\n",
            "Epoch: 4, Average Epoch Loss: 2.295336306889852\n",
            "Epoch: 5, Average Epoch Loss: 2.2953363130887348\n",
            "Epoch: 6, Average Epoch Loss: 2.2953363183339435\n",
            "Epoch: 7, Average Epoch Loss: 2.2953363200823467\n",
            "Epoch: 8, Average Epoch Loss: 2.2953363060951233\n",
            "Epoch: 9, Average Epoch Loss: 2.295336319128672\n",
            "Epoch: 10, Average Epoch Loss: 2.2953363149960837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evalaution"
      ],
      "metadata": {
        "id": "X776lkVyO4F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBni6vZzO5vy",
        "outputId": "74f30d4a-563c-4225-cc99-cb84c40de7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** It is important to explicitly tell the model that it is in evaluaiton mode. The puporse of doing this is to ensure that model does not simulate the training process behaviour when we are evaluating or testing our model on unseen data. Doing this is to avoid situations, such as:\n",
        "- When the behaviour of the dropout layers needs to be nullified; once the model has been trained.\n",
        "- Secondly, during batch normalization real-time mean and `std` calculations are not required to be made and updated; we just use the one's finalised during training."
      ],
      "metadata": {
        "id": "D-QJvvEvO7v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0"
      ],
      "metadata": {
        "id": "j50FbKhTNakZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "  for batch_idx, (features, labels) in enumerate(test_loader):\n",
        "\n",
        "    y_pred = model(features)\n",
        "\n",
        "    _, predicted = torch.max(y_pred.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()"
      ],
      "metadata": {
        "id": "qE4qZG4hp-cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vcq5ughrFxu",
        "outputId": "f28062f6-68e1-4321-e420-964853975b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10358333333333333\n"
          ]
        }
      ]
    }
  ]
}